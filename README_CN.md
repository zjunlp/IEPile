<p align="left">
    <b> <a href="https://github.com/zjunlp/IEPile/tree/main">English</a> | ç®€ä½“ä¸­æ–‡ </b>
</p>

# IEPileï¼šå¤§è§„æ¨¡ä¿¡æ¯æŠ½å–è¯­æ–™åº“

è¿™æ˜¯è®ºæ–‡ [IEPile: Unearthing Large-Scale Schema-Based Information Extraction Corpus](https://arxiv.org/abs/2402.14710) çš„å®˜æ–¹ä»“åº“ã€‚


[**æ•°æ®é›†**](https://huggingface.co/datasets/zjunlp/iepile) |
[**è®ºæ–‡**](https://huggingface.co/papers/2402.14710) |
[**ä½¿ç”¨æ–¹æ³•**](./README_CN.md#3ä½¿ç”¨iepileè®­ç»ƒæ¨¡å‹) |
[**å±€é™æ€§**](./README_CN.md#8å±€é™) |
[**å£°æ˜å’Œè®¸å¯**](./README_CN.md#7å£°æ˜å’Œè®¸å¯) |
[**å¼•ç”¨**](./README_CN.md#9å¼•ç”¨)

> è¯·æ³¨æ„ï¼Œæˆ‘ä»¬çš„IEPileå¯èƒ½ä¼šè¿›è¡Œ**æ›´æ–°**ï¼ˆä¸€æ—¦å‘å¸ƒæ›´æ–°ï¼Œæˆ‘ä»¬å°†é€šçŸ¥æ‚¨ï¼‰ã€‚å»ºè®®ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬ã€‚


- [IEPileï¼šå¤§è§„æ¨¡ä¿¡æ¯æŠ½å–è¯­æ–™åº“](#iepileå¤§è§„æ¨¡ä¿¡æ¯æŠ½å–è¯­æ–™åº“)
  - [æ–°é—»](#æ–°é—»)
  - [1.ä»‹ç»](#1ä»‹ç»)
  - [2.æ•°æ®](#2æ•°æ®)
    - [2.1IEPileçš„æ„é€ ](#21iepileçš„æ„é€ )
    - [2.2IEPileçš„æ•°æ®æ ¼å¼](#22iepileçš„æ•°æ®æ ¼å¼)
  - [3.ä½¿ç”¨IEPileè®­ç»ƒæ¨¡å‹](#3ä½¿ç”¨iepileè®­ç»ƒæ¨¡å‹)
    - [3.1ç¯å¢ƒ](#31ç¯å¢ƒ)
    - [3.2ä¸‹è½½æ•°æ®å’Œæ¨¡å‹](#32ä¸‹è½½æ•°æ®å’Œæ¨¡å‹)
    - [3.3LoRAå¾®è°ƒ](#33loraå¾®è°ƒ)
  - [4.é¢†åŸŸå†…æ•°æ®ç»§ç»­è®­ç»ƒ](#4é¢†åŸŸå†…æ•°æ®ç»§ç»­è®­ç»ƒ)
    - [4.1è®­ç»ƒæ•°æ®è½¬æ¢](#41è®­ç»ƒæ•°æ®è½¬æ¢)
    - [4.2ç»§ç»­è®­ç»ƒ](#42ç»§ç»­è®­ç»ƒ)
    - [4.3OneKEç»§ç»­è®­ç»ƒ](#43onekeç»§ç»­è®­ç»ƒ)
      - [4.3.1å…¨ç›‘ç£è®­ç»ƒ](#431å…¨ç›‘ç£è®­ç»ƒ)
      - [4.3.2Loraè®­ç»ƒ](#432loraè®­ç»ƒ)
  - [5.é¢„æµ‹](#5é¢„æµ‹)
    - [5.1æµ‹è¯•æ•°æ®è½¬æ¢](#51æµ‹è¯•æ•°æ®è½¬æ¢)
    - [5.2IEPileæµ‹è¯•æ•°æ®](#52iepileæµ‹è¯•æ•°æ®)
    - [5.3åŸºç¡€æ¨¡å‹+Loraé¢„æµ‹](#53åŸºç¡€æ¨¡å‹loraé¢„æµ‹)
    - [5.4IEä¸“ç”¨æ¨¡å‹é¢„æµ‹](#54ieä¸“ç”¨æ¨¡å‹é¢„æµ‹)
  - [æ¨¡å‹ä½¿ç”¨](#æ¨¡å‹ä½¿ç”¨)
    - [æ¨¡å‹ä¸‹è½½](#æ¨¡å‹ä¸‹è½½)
    - [ç¯å¢ƒå®‰è£…](#ç¯å¢ƒå®‰è£…)
    - [å¿«é€Ÿè¿è¡Œ](#å¿«é€Ÿè¿è¡Œ)
    - [vLLM æ¨ç†](#vllm-æ¨ç†)
    - [ollama æ¨ç†](#ollama-æ¨ç†)
    - [åœ¨ Mac ä¸Šæ¨ç†](#åœ¨-mac-ä¸Šæ¨ç†)
    - [å¤šå¡æ¨ç†](#å¤šå¡æ¨ç†)
  - [6.è¯„ä¼°](#6è¯„ä¼°)
  - [7.å£°æ˜å’Œè®¸å¯](#7å£°æ˜å’Œè®¸å¯)
  - [8.å±€é™](#8å±€é™)
  - [9.å¼•ç”¨](#9å¼•ç”¨)
  - [10.è‡´è°¢](#10è‡´è°¢)


## æ–°é—»
* [2024/05] è®ºæ–‡ [IEPile: Unearthing Large-Scale Schema-Based Information Extraction Corpus](https://doi.org/10.48550/arXiv.2402.14710) è¢« ACL 2024ä¼šè®®å½•ç”¨ã€‚
* [2024/04] å‘å¸ƒä¸­è‹±åŒè¯­å¤§æ¨¡å‹çŸ¥è¯†æŠ½å–æ¡†æ¶[OneKE](http://oneke.openkg.cn/)ï¼ŒåŒæ—¶å¼€æºåŸºäºChinese-Alpaca-2-13Bå…¨å‚æ•°å¾®è°ƒçš„ç‰ˆæœ¬ã€‚
* [2024/02] å‘å¸ƒå¤§è§„æ¨¡(`0.32B` tokens)**åŒè¯­**(ä¸­æ–‡å’Œè‹±æ–‡)ä¿¡æ¯æŠ½å–(IE)æŒ‡ä»¤æ•°æ®é›†[IEPile](https://huggingface.co/datasets/zjunlp/iepie), ä»¥åŠåŸºäº `IEPile` è®­ç»ƒçš„ä¸¤ä¸ªæ¨¡å‹[baichuan2-13b-iepile-lora](https://huggingface.co/zjunlp/baichuan2-13b-iepile-lora)ã€[llama2-13b-iepile-lora](https://huggingface.co/zjunlp/llama2-13b-iepile-lora)ã€‚
* [2023/10] æˆ‘ä»¬å‘å¸ƒäº†ä¸€ä¸ªæ–°çš„**åŒè¯­**(ä¸­æ–‡å’Œè‹±æ–‡)åŸºäºä¸»é¢˜çš„ä¿¡æ¯æŠ½å–(IE)æŒ‡ä»¤æ•°æ®é›†ï¼Œåä¸º[InstructIE](https://huggingface.co/datasets/zjunlp/InstructIE)å’Œ[è®ºæ–‡](https://arxiv.org/abs/2305.11527)ã€‚
* [2023/08] æˆ‘ä»¬æ¨å‡ºäº†ä¸“ç”¨äºä¿¡æ¯æŠ½å–(IE)çš„13Bæ¨¡å‹ï¼Œåä¸º[knowlm-13b-ie](https://huggingface.co/zjunlp/knowlm-13b-ie/tree/main)ã€‚
* [2023/05] æˆ‘ä»¬å¯åŠ¨äº†åŸºäºæŒ‡ä»¤çš„ä¿¡æ¯æŠ½å–é¡¹ç›®ã€‚



## 1.ä»‹ç»


**`IEPile`** æ•°æ®é›†ä¸‹è½½é“¾æ¥ï¼š[Google Drive](https://drive.google.com/file/d/1jPdvXOTTxlAmHkn5XkeaaCFXQkYJk5Ng/view?usp=sharing) | [Hugging Face](https://huggingface.co/datasets/zjunlp/iepile) | [WiseModel](https://wisemodel.cn/datasets/zjunlp/IEPile) | [ModelScpoe](https://modelscope.cn/datasets/ZJUNLP/IEPile)


> è¯·æ³¨æ„ï¼Œä»¥ä¸Šæä¾›çš„æ•°æ®é›†é“¾æ¥ä¸­æ‰€å«æ•°æ®å·²ç»æ’é™¤äº†ä¸ACE2005æ•°æ®é›†ç›¸å…³çš„éƒ¨åˆ†ã€‚è‹¥æ‚¨éœ€è¦è®¿é—®æœªç»è¿‡æ»¤çš„å®Œæ•´æ•°æ®é›†ï¼Œå¹¶ä¸”å·²æˆåŠŸè·å–æ‰€éœ€çš„æƒé™ï¼Œæ•¬è¯·é€šè¿‡ç”µå­é‚®ä»¶æ–¹å¼è”ç³» guihonghao@zju.edu.cn æˆ– zhangningyu@zju.edu.cnã€‚æˆ‘ä»¬å°†æä¾›å®Œæ•´æ•°æ®é›†èµ„æºã€‚


**`LLaMA2-IEPile`** | **`Baichuan2-IEPile`** | **`OneKE`** æ¨¡å‹ä¸‹è½½é“¾æ¥ï¼š[zjunlp/llama2-13b-iepile-lora](https://huggingface.co/zjunlp/llama2-13b-iepile-lora/tree/main) | [zjunlp/baichuan2-13b-iepile-lora](https://huggingface.co/zjunlp/baichuan2-13b-iepile-lora) | [zjunlp/OneKE](https://huggingface.co/zjunlp/OneKE)


![statistic](./assets/statistic.jpg)

æˆ‘ä»¬ç²¾å¿ƒæ”¶é›†å¹¶æ¸…æ´—äº†ç°æœ‰çš„ä¿¡æ¯æŠ½å–ï¼ˆIEï¼‰æ•°æ®ï¼Œå…±æ•´åˆäº†`26`ä¸ª**è‹±æ–‡**IEæ•°æ®é›†å’Œ`7`ä¸ª**ä¸­æ–‡**IEæ•°æ®é›†ã€‚å¦‚å›¾1æ‰€ç¤ºï¼Œè¿™äº›æ•°æ®é›†è¦†ç›–äº†åŒ…æ‹¬**é€šç”¨**ã€**åŒ»å­¦**ã€**é‡‘è**ç­‰å¤šä¸ªé¢†åŸŸã€‚

æœ¬ç ”ç©¶é‡‡ç”¨äº†æ‰€æå‡ºçš„â€œ`åŸºäºschemaçš„è½®è¯¢æŒ‡ä»¤æ„é€ æ–¹æ³•`â€ï¼ŒæˆåŠŸåˆ›å»ºäº†ä¸€ä¸ªåä¸º **IEPile** çš„å¤§è§„æ¨¡é«˜è´¨é‡**åŒè¯­**(ä¸­æ–‡å’Œè‹±æ–‡)IEæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼ŒåŒ…å«çº¦`0.32B` tokensã€‚

åŸºäº**IEPile**ï¼Œæˆ‘ä»¬å¯¹ `Baichuan2-13B-Chat` å’Œ `LLaMA2-13B-Chat` æ¨¡å‹åº”ç”¨äº† `Lora` æŠ€æœ¯è¿›è¡Œäº†å¾®è°ƒã€‚å®éªŒè¯æ˜ï¼Œå¾®è°ƒåçš„ `Baichuan2-IEPile` å’Œ `LLaMA2-IEPile` æ¨¡å‹åœ¨å…¨ç›‘ç£è®­ç»ƒé›†ä¸Šå–å¾—äº†å¯æ¯”çš„ç»“æœï¼Œå¹¶ä¸”åœ¨**é›¶æ ·æœ¬ä¿¡æ¯æŠ½å–ä»»åŠ¡**ä¸­å–å¾—äº†æå‡ã€‚


<details>
  <summary><b>é›¶æ ·æœ¬ä¿¡æ¯æŠ½å–ç»“æœ</b></summary>

![zero_en](./assets/zero_en.jpg)

![zero_zh](./assets/zero_zh.jpg)

</details>

<details>
  <summary><b>å…¨ç›‘ç£æ•°æ®é›†ç»“æœ</b></summary>

![supervision_ner](./assets/supervision_ner.jpg)

![supervision_re](./assets/supervision_re.jpg)

![supervision_ee](./assets/supervision_ee.jpg)

</details>


## 2.æ•°æ®


### 2.1IEPileçš„æ„é€ 

æˆ‘ä»¬ä¸“æ³¨äº**åŸºäºæŒ‡ä»¤çš„ä¿¡æ¯æŠ½å–**ï¼Œå› æ­¤æŒ‡ä»¤ä¸­çš„schemaçš„æ„é€ è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒåæ˜ ç€å…·ä½“æŠ½å–éœ€æ±‚ï¼Œæ˜¯åŠ¨æ€å¯å˜çš„ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶åœ¨æ„é€ æŒ‡ä»¤æ—¶å¾€å¾€é‡‡å–ä¸€ç§**è¾ƒä¸ºç²—æ”¾çš„schemaå¤„ç†ç­–ç•¥**ï¼Œå³åˆ©ç”¨æ ‡ç­¾é›†å†…**å…¨éƒ¨schema**è¿›è¡ŒæŒ‡ä»¤æ„å»ºã€‚è¿™ç§æ–¹æ³•æ½œåœ¨åœ°å­˜åœ¨2ä¸ªé‡è¦çš„é—®é¢˜ï¼š
1. **è®­ç»ƒå’Œè¯„ä¼°é˜¶æ®µschemaè¯¢é—®çš„æ•°é‡ä¸ä¸€è‡´ï¼Œå³ä½¿è¿™äº›schemaåœ¨å†…å®¹ä¸Šç›¸ä¼¼ï¼Œå¯èƒ½æŸå®³æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›**ã€‚è‹¥è®­ç»ƒè¿‡ç¨‹ä¸­æ¯æ¬¡è¯¢é—®çš„schemaæ•°é‡å¤§çº¦æ˜¯20ä¸ªï¼Œè€Œè¯„ä¼°æ—¶è¯¢é—®çš„æ˜¯10ä¸ªæˆ–30ä¸ªschemaï¼Œå³ä½¿è¿™äº›schemaåœ¨å†…å®¹ä¸Šä¸è®­ç»ƒé˜¶æ®µç›¸ä¼¼ï¼Œæ¨¡å‹æ€§èƒ½ä»å¯èƒ½å—åˆ°å½±å“ã€‚
2. **æŒ‡ä»¤ä¸­çš„schemaä¹‹é—´çš„å¯¹æ¯”æ€§ä¸è¶³**ã€‚è¯­ä¹‰è¿‘ä¼¼çš„schemaï¼Œå¦‚â€œè£å‘˜â€ã€â€œç¦»èŒâ€ä¸â€œè§£é›‡â€ï¼Œå®ƒä»¬çš„è¯­ä¹‰æ¨¡ç³Šæ€§å¯èƒ½é€ æˆæ¨¡å‹æ··æ·†ã€‚è¿™ç±»æ˜“æ··æ·†çš„æ¨¡å¼åº”å½“åœ¨æŒ‡ä»¤é›†ä¸­æ›´ä¸ºé¢‘ç¹åœ°å‡ºç°ã€‚
   
å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºå¦‚ä¸‹è§£å†³æ–¹æ¡ˆï¼š1ã€`æ„é€ éš¾è´Ÿæ ·æœ¬å­—å…¸`ï¼›2ã€`è½®è¯¢å¼çš„æŒ‡ä»¤ç”Ÿæˆ`ã€‚

![iepile](./assets/iepile.jpg)


<details>
  <summary><b>éš¾è´Ÿæ ·æœ¬</b></summary>


å‡è®¾æ•°æ®é›† $\mathcal{D}$ æœ‰å…¶å…¨é‡æ ‡ç­¾é›† $L$ï¼Œ $\mathcal{D}$ ä¸­æŸä¸€æ–‡æœ¬ $S$ï¼Œ $S$ ä¸­çœŸå®å­˜åœ¨çš„æ ‡ç­¾æ„æˆ**æ­£ä¾‹æ ‡ç­¾é›†** $Pos\_L$ï¼Œè€Œä¸å­˜åœ¨çš„æ ‡ç­¾åˆ™å½¢æˆ**è´Ÿä¾‹æ ‡ç­¾é›†** $Neg\_L$ã€‚åœ¨æˆ‘ä»¬çš„åˆ†æä¸­ï¼Œæˆ‘ä»¬å‘ç°æ¨¡å‹è¯¯åˆ¤çš„ä¸»è¦åŸå› åœ¨äºschemaçš„**è¯­ä¹‰æ¨¡ç³Š**ï¼Œå¯¼è‡´äº†æ¨¡å‹çš„æ··æ·†ã€‚ä¼ ç»Ÿæ–¹æ³•ä¸­ï¼Œè´Ÿä¾‹æ ‡ç­¾ $Neg\_L$é€šå¸¸ç®€å•åœ°å®šä¹‰ä¸º $L - Pos\_L$ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å¿½è§†äº†ä¸€ä¸ªé‡è¦æ–¹é¢ï¼šéœ€è¦ç‰¹åˆ«æ³¨æ„é‚£äº›ä¸æ­£ä¾‹æ ‡ç­¾**è¯­ä¹‰ç›¸è¿‘**çš„è´Ÿä¾‹æ ‡ç­¾ã€‚å—**å¯¹æ¯”å­¦ä¹ **ç†è®ºçš„å¯å‘ã€‚æˆ‘ä»¬æ„é€ äº†ä¸€ä¸ª**éš¾è´Ÿæ ·æœ¬å­—å…¸** $\mathcal{D}$ï¼Œå…¶é”®å€¼å¯¹åº”çš„æ˜¯SchemaåŠå…¶è¯­ä¹‰ä¸Šç›¸è¿‘çš„Schemaé›†ã€‚å› æ­¤**éš¾è´Ÿæ ·æœ¬é›†** $Hard\_L = \mathcal{D}[Pos\_L]$ã€‚ç„¶è€Œï¼Œè‹¥ $Neg\_L$ ä»…ç”± $Hard\_L$ æ„æˆä¼šç¼ºå°‘è¶³å¤Ÿçš„è´Ÿä¾‹è®©æ¨¡å‹å­¦ä¹ ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å®šä¹‰å…¶ä»–è´Ÿæ ·æœ¬ $Other\_L = L - Hard\_L$ï¼Œæœ€ç»ˆï¼Œè´Ÿä¾‹æ ‡ç­¾ $Neg\_L$ ç”± $Hard\_L$ å’Œå°‘é‡çš„ $Other\_L$ ç»„æˆã€‚è¿™ç§éš¾è´Ÿæ ·æœ¬çš„æ„å»ºæ—¨åœ¨ä¿ƒè¿›è¯­ä¹‰è¿‘ä¼¼çš„æ¨¡å¼æ›´é¢‘ç¹åœ°å‡ºç°åœ¨æŒ‡ä»¤ä¸­ï¼ŒåŒæ—¶ä¹Ÿèƒ½åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„æƒ…å†µä¸‹**å‡å°‘è®­ç»ƒæ ·æœ¬é‡**ï¼ˆä¾‹å¦‚ï¼ŒåŸæœ¬éœ€12ä¸ªæŒ‡ä»¤é›†çš„49ä¸ªschemaå¯å‡è‡³3ä¸ªï¼‰ã€‚

</details>


<details>
  <summary><b>è½®è¯¢å¼çš„æŒ‡ä»¤ç”Ÿæˆ</b></summary>

åœ¨å®Œæˆäº†ä¸Šè¿°æ­¥éª¤åï¼Œæˆ‘ä»¬å¾—åˆ°äº†æœ€ç»ˆçš„schemaé›†åˆ $L'=Pos\_L + Neg\_L$ã€‚åœ¨åŸºäºschemaçš„ä¿¡æ¯æŠ½å–ï¼ˆIEï¼‰æŒ‡ä»¤æ„é€ ä¸­ï¼Œschemaçš„ä½œç”¨è‡³å…³é‡è¦ï¼Œå®ƒç›´æ¥å†³å®šäº†æ¨¡å‹éœ€è¦æŠ½å–çš„ä¿¡æ¯ç±»å‹ï¼Œå¹¶ä¸”åæ˜ äº†ç”¨æˆ·çš„å…·ä½“éœ€æ±‚ã€‚ä¼ ç»Ÿåšæ³•é€šå¸¸å°†å®Œæ•´çš„schemaä¸€æ¬¡æ€§æ•´åˆå…¥æŒ‡ä»¤ä¸­ï¼Œç„¶è€Œï¼Œåœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬é‡‡çº³äº†ä¸€ç§**è½®è¯¢å¼æ–¹æ³•**ï¼Œé™åˆ¶æ¯æ¬¡è¯¢é—®çš„schemaæ•°é‡ä¸º $split\_num$ ä¸ªï¼Œå–å€¼èŒƒå›´åœ¨4è‡³6ä¹‹é—´ã€‚å› æ­¤ $L'$ å°†è¢«åˆ†ä¸º $|L'|/split\_num$ ä¸ªæ‰¹æ¬¡è¿›è¡Œè¯¢é—®ï¼Œæ¯æ‰¹æ¬¡è¯¢é—® $split\_num$ ä¸ªschemaã€‚å³ä½¿åœ¨è¯„ä¼°é˜¶æ®µè¯¢é—®çš„schemaæ•°ç›®ä¸è®­ç»ƒæ—¶ä¸åŒï¼Œé€šè¿‡è½®è¯¢æœºåˆ¶ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¯¢é—®æ•°é‡å¹³å‡åˆ†æ•£è‡³ $split\_num$ ä¸ªï¼Œä»è€Œç¼“è§£æ³›åŒ–æ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚

</details>



### 2.2IEPileçš„æ•°æ®æ ¼å¼

`IEPile` ä¸­çš„æ¯æ¡æ•°æ®å‡åŒ…å« `task`, `source`, `instruction`, `output` 4ä¸ªå­—æ®µ

ä»¥ä¸‹æ˜¯ä¸€æ¡**æ•°æ®å®ä¾‹**ï¼š

```json
{
  "task": "NER", 
  "source": "MSRA", 
  "instruction": "{\"instruction\": \"ä½ æ˜¯ä¸“é—¨è¿›è¡Œå®ä½“æŠ½å–çš„ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„å®ä½“ï¼Œä¸å­˜åœ¨çš„å®ä½“ç±»å‹è¿”å›ç©ºåˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚\", \"schema\": [\"ç»„ç»‡æœºæ„\", \"åœ°ç†ä½ç½®\", \"äººç‰©\"], \"input\": \"å¯¹äºåº·æœ‰ä¸ºã€æ¢å¯è¶…ã€è°­å—£åŒã€ä¸¥å¤è¿™äº›ä»æ—§æ–‡åŒ–è¥å’ä¸­èµ°æ¥çš„å¹´è½»â€œå¸ƒè¡£â€ï¼Œä»–ä»¬èƒŒè´Ÿç€æ²‰é‡çš„å†å²åŒ…è¢±ï¼Œèƒ½å¤ŸæŒ£è„±æ—§ä¼ ç»Ÿçš„æŸç¼šï¼Œä¸ºæ‹¯æ•‘æ°‘æ—çš„å±äº¡è€ŒçŒ®èº«ï¼Œå®åœ¨æ˜¯ä¸­åæ°‘æ—çš„è„Šæ¢ã€‚\"}", 
  "output": "{\"ç»„ç»‡æœºæ„\": [], \"åœ°ç†ä½ç½®\": [\"ä¸­å\"], \"äººç‰©\": [\"åº·æœ‰ä¸º\", \"æ¢å¯è¶…\", \"è°­å—£åŒ\", \"ä¸¥å¤\"]}"
}
```

è¯¥æ•°æ®å®ä¾‹æ‰€å±ä»»åŠ¡æ˜¯ `NER`, æ‰€å±æ•°æ®é›†æ˜¯ `MSRA`, å¾…æŠ½å–çš„schemaåˆ—è¡¨æ˜¯ ["ç»„ç»‡æœºæ„", "åœ°ç†ä½ç½®", "äººç‰©"], å¾…æŠ½å–çš„æ–‡æœ¬æ˜¯"*å¯¹äºåº·æœ‰ä¸ºã€æ¢å¯è¶…ã€è°­å—£åŒã€ä¸¥å¤è¿™äº›ä»æ—§æ–‡åŒ–è¥å’ä¸­èµ°æ¥çš„å¹´è½»â€œå¸ƒè¡£â€ï¼Œä»–ä»¬èƒŒè´Ÿç€æ²‰é‡çš„å†å²åŒ…è¢±ï¼Œèƒ½å¤ŸæŒ£è„±æ—§ä¼ ç»Ÿçš„æŸç¼šï¼Œä¸ºæ‹¯æ•‘æ°‘æ—çš„å±äº¡è€ŒçŒ®èº«ï¼Œå®åœ¨æ˜¯ä¸­åæ°‘æ—çš„è„Šæ¢ã€‚*", è¾“å‡ºæ˜¯ `{"ç»„ç»‡æœºæ„": [], "åœ°ç†ä½ç½®": ["ä¸­å"], "äººç‰©": ["åº·æœ‰ä¸º", "æ¢å¯è¶…", "è°­å—£åŒ", "ä¸¥å¤"]}`

> æ³¨æ„è¾“å‡ºä¸­çš„ schema é¡ºåºä¸ instruction ä¸­çš„ schema é¡ºåºä¸€è‡´


<details>
  <summary><b>æ›´å¤šä»»åŠ¡çš„æ•°æ®å®ä¾‹</b></summary>

```json
{
  "task": "RE", 
  "source": "DuIE2.0", 
  "instruction": "{\"instruction\": \"ä½ æ˜¯ä¸“é—¨è¿›è¡Œå…³ç³»æŠ½å–çš„ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„å…³ç³»ä¸‰å…ƒç»„ï¼Œä¸å­˜åœ¨çš„å…³ç³»è¿”å›ç©ºåˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚\", \"schema\": [\"å›½ç±\", \"ä½œè€…\", \"æ¯•ä¸šé™¢æ ¡\", \"ä¸»è§’\"], \"input\": \"å¯¹æ¯”æ—¥æœ¬åŠ¨ç”»ç”µå½±åœ¨ä¸­æ—¥ä¸¤å›½çš„ç¥¨æˆ¿è¡¨ç°ï¼Œå¯ä»¥å‘ç°ï¼Œæ—¥æ¼«é£æ ¼çš„åŠ¨ç”»ï¼Œåœ¨å›½å†…ä¹Ÿæœ‰åœˆå±‚é™åˆ¶ï¼Œå³ä¾¿æ˜¯å®«å´éªã€Šåƒä¸åƒå¯»ã€‹ã€æ–°æµ·è¯šã€Šä½ çš„åå­—ã€‹ï¼Œè¿™ç±»æ—¥æœ¬åŠ¨ç”»ç¥¨æˆ¿æ¦œé¦–çš„ç”µå½±ï¼Œå›½å†…ç¥¨æˆ¿ä¹Ÿåœç•™åœ¨5äº¿å·¦å³\"}", 
  "output": "{\"å›½ç±\": [], \"ä½œè€…\": [{\"subject\": \"ä½ çš„åå­—\", \"object\": \"æ–°æµ·è¯š\"}], \"æ¯•ä¸šé™¢æ ¡\": [], \"ä¸»è§’\": []}"
}

{
  "task": "EE", 
  "source": "DuEE1.0", 
  "instruction": "{\"instruction\": \"ä½ æ˜¯ä¸“é—¨è¿›è¡Œäº‹ä»¶æå–çš„ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„äº‹ä»¶ï¼Œä¸å­˜åœ¨çš„äº‹ä»¶è¿”å›ç©ºåˆ—è¡¨ï¼Œä¸å­˜åœ¨çš„è®ºå…ƒè¿”å›NANï¼Œå¦‚æœè®ºå…ƒå­˜åœ¨å¤šå€¼è¯·è¿”å›åˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚\", \"schema\": [{\"event_type\": \"äººç”Ÿ-æ±‚å©š\", \"trigger\": true, \"arguments\": [\"æ±‚å©šå¯¹è±¡\"]}, {\"event_type\": \"äººç”Ÿ-è®¢å©š\", \"trigger\": true, \"arguments\": [\"è®¢å©šä¸»ä½“\", \"æ—¶é—´\"]}, {\"event_type\": \"ç¾å®³/æ„å¤–-å/å®å¡Œ\", \"trigger\": true, \"arguments\": [\"å—ä¼¤äººæ•°\", \"åå¡Œä¸»ä½“\"]}, {\"event_type\": \"äººç”Ÿ-å¤±è”\", \"trigger\": true, \"arguments\": [\"åœ°ç‚¹\", \"å¤±è”è€…\"]}], \"input\": \"éƒ­ç¢§å©·è®¢å©šåï¼Œå¡«èµ„æ–™ä¾æ—§æƒ³è¦å¡«å•èº«ï¼Œæœ‰è°æ³¨æ„å‘ä½è¯´äº†ä»€ä¹ˆï¼Ÿ\"}", 
  "output": "{\"äººç”Ÿ-æ±‚å©š\": [], \"äººç”Ÿ-è®¢å©š\": [{\"trigger\": \"è®¢å©š\", \"arguments\": {\"è®¢å©šä¸»ä½“\": [\"å‘ä½\", \"éƒ­ç¢§å©·\"], \"æ—¶é—´\": \"NAN\"}}], \"ç¾å®³/æ„å¤–-å/å®å¡Œ\": [], \"äººç”Ÿ-å¤±è”\": []}"
}
```

</details>

ä»¥ä¸‹æ˜¯å„å­—æ®µçš„è¯´æ˜: 

| å­—æ®µ | è¯´æ˜ |
| :---: | :---: |
| task | è¯¥å®ä¾‹æ‰€å±çš„ä»»åŠ¡, (`NER`ã€`RE`ã€`EE`ã€`EET`ã€`EEA`) 5ç§ä»»åŠ¡ä¹‹ä¸€ã€‚ |
| source | è¯¥å®ä¾‹æ‰€å±çš„æ•°æ®é›† |
| instruction | è¾“å…¥æ¨¡å‹çš„æŒ‡ä»¤, ç»è¿‡json.dumpså¤„ç†æˆJSONå­—ç¬¦ä¸², ç”±`"instruction"`, `"schema"`, `"input"`ä¸‰éƒ¨åˆ†ç»„æˆ |
| output | è¾“å‡º, é‡‡ç”¨å­—å…¸çš„jsonå­—ç¬¦ä¸²çš„æ ¼å¼, keyæ˜¯schema, valueæ˜¯æŠ½å–å‡ºçš„å†…å®¹ |


åœ¨`IEPile`ä¸­, **`instruction`** çš„æ ¼å¼é‡‡çº³äº†ç±»JSONå­—ç¬¦ä¸²çš„ç»“æ„ï¼Œå®è´¨ä¸Šæ˜¯ä¸€ç§å­—å…¸å‹å­—ç¬¦ä¸²ï¼Œå®ƒç”±ä»¥ä¸‹ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†æ„æˆï¼š
(1) **`'instruction'`**: ä»»åŠ¡æè¿°, å®ƒæ¦‚è¿°äº†æŒ‡ä»¤çš„æ‰§è¡Œä»»åŠ¡(`NER`ã€`RE`ã€`EE`ã€`EET`ã€`EEA`ä¹‹ä¸€)ã€‚
(2) **`'schema'`**: å¾…æŠ½å–çš„schema(`å®ä½“ç±»å‹`, `å…³ç³»ç±»å‹`, `äº‹ä»¶ç±»å‹`)åˆ—è¡¨ã€‚
(3) **`'input'`**: å¾…æŠ½å–çš„æ–‡æœ¬ã€‚


[instruction.py](./ie2instruction/convert/utils/instruction.py) ä¸­æä¾›äº†å„ä¸ªä»»åŠ¡çš„æŒ‡ä»¤æ¨¡ç‰ˆã€‚



## 3.ä½¿ç”¨IEPileè®­ç»ƒæ¨¡å‹

### 3.1ç¯å¢ƒ

åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æŒ‰ç…§ä¸‹é¢çš„æŒ‡å¯¼åˆ›å»ºé€‚å½“çš„**è™šæ‹Ÿç¯å¢ƒ**ï¼š

```bash
conda create -n IEPile python=3.9   # åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda activate IEPile               # æ¿€æ´»ç¯å¢ƒ
pip install -r requirements.txt     # å®‰è£…ä¾èµ– 
```

### 3.2ä¸‹è½½æ•°æ®å’Œæ¨¡å‹

**`IEPile`** æ•°æ®é›†ä¸‹è½½é“¾æ¥ï¼š[Google Drive](https://drive.google.com/file/d/1jPdvXOTTxlAmHkn5XkeaaCFXQkYJk5Ng/view?usp=sharing) | [Hugging Face](https://huggingface.co/datasets/zjunlp/IEPile)

```python
IEPile
â”œâ”€â”€ train.json    # è®­ç»ƒé›†
â””â”€â”€ dev.json      # éªŒè¯é›†
```

ä»¥ä¸‹æ˜¯æœ¬ä»“åº“ä»£ç æ”¯æŒçš„ä¸€äº›åŸºç¡€æ¨¡å‹ï¼š[[llama](https://huggingface.co/meta-llama), [alpaca](https://github.com/tloen/alpaca-lora), [vicuna](https://huggingface.co/lmsys), [zhixi](https://github.com/zjunlp/KnowLM), [falcon](https://huggingface.co/tiiuae), [baichuan](https://huggingface.co/baichuan-inc), [chatglm](https://huggingface.co/THUDM), [qwen](https://huggingface.co/Qwen), [moss](https://huggingface.co/fnlp), [openba](https://huggingface.co/OpenBA)]



```bash
mkdir data         # æ•°æ®æ”¾è¿™
mkdir models       # åŸºç¡€æ¨¡å‹æ”¾è¿™
mkdir results      # é¢„æµ‹ç»“æœæ”¾è¿™
mkdir lora         # loraå¾®è°ƒç»“æœæ”¾è¿™
```


### 3.3LoRAå¾®è°ƒ

> é‡è¦æç¤ºï¼šä»¥ä¸‹çš„æ‰€æœ‰å‘½ä»¤å‡åº”åœ¨`IEPile`ç›®å½•ä¸‹æ‰§è¡Œã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æƒ³è¿è¡Œå¾®è°ƒè„šæœ¬ï¼Œæ‚¨åº”è¯¥ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤ï¼šbash ft_scripts/fine_llama.bashã€‚è¯·ç¡®ä¿æ‚¨çš„å½“å‰å·¥ä½œç›®å½•æ­£ç¡®ã€‚
> è¯·ç¡®ä¿è®­ç»ƒ/éªŒè¯æ–‡ä»¶ä¸­æ¯æ¡æ•°æ®åŒ…å« `instruction`, `output` å­—æ®µã€‚


```bash
output_dir='lora/llama2-13b-chat-v1'
mkdir -p ${output_dir}
CUDA_VISIBLE_DEVICES="0,1,2,3" torchrun --nproc_per_node=4 --master_port=1287 src/finetune.py \
    --do_train --do_eval \
    --overwrite_output_dir \
    --model_name_or_path 'models/llama2-13b-chat' \
    --stage 'sft' \
    --model_name 'llama' \
    --template 'llama2' \
    --train_file 'data/NER/train.json' \
    --valid_file 'data/NER/dev.json' \
    --output_dir=${output_dir} \
    --per_device_train_batch_size 2 \
    --per_device_eval_batch_size 2 \
    --gradient_accumulation_steps 4 \
    --preprocessing_num_workers 16 \
    --num_train_epochs 10 \
    --learning_rate 5e-5 \
    --max_grad_norm 0.5 \
    --optim "adamw_torch" \
    --max_source_length 400 \
    --cutoff_len 700 \
    --max_target_length 300 \
    --evaluation_strategy "epoch" \
    --save_strategy "epoch" \
    --save_total_limit 10 \
    --lora_r 16 \
    --lora_alpha 32 \
    --lora_dropout 0.05 \
    --bf16 \
    --deepspeed configs/ds_config_bf16.json
```

* `CUDA_VISIBLE_DEVICES="0,1,2,3"`: æŒ‡å®šå“ªäº›GPUå¯ç”¨äºå½“å‰çš„è®­ç»ƒä»»åŠ¡ã€‚è¿™é‡Œçš„"0,1,2,3"æ„å‘³ç€ä½¿ç”¨ç¼–å·ä¸º0ã€1ã€2ã€3çš„å››ä¸ªGPUã€‚å¦‚æœä½ çš„æœºå™¨ä¸Šæœ‰å¤šäºå››ä¸ªGPUï¼Œè¿™ä¸ªè®¾ç½®å¯ä»¥è®©ä½ é€‰æ‹©ä½¿ç”¨å“ªå››ä¸ªã€‚
* `--nproc_per_node=4`: æŒ‡å®šæ¯ä¸ªèŠ‚ç‚¹ä¸Šè¦å¯åŠ¨çš„è¿›ç¨‹æ•°ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå› ä¸ºæŒ‡å®šäº†4ä¸ªGPUï¼Œæ‰€ä»¥ä¹Ÿéœ€è¦å¯åŠ¨4ä¸ªè¿›ç¨‹ï¼Œæ¯ä¸ªè¿›ç¨‹å¯¹åº”ä¸€ä¸ªGPUã€‚
* å¯¹äºåªä½¿ç”¨**å•ä¸ªGPU**è¿›è¡Œè®­ç»ƒçš„æƒ…å†µï¼Œå¯ä»¥é€šè¿‡`CUDA_VISIBLE_DEVICES=0 python src/finetune.py`å‘½ä»¤æ¥å¯åŠ¨è®­ç»ƒä»»åŠ¡ï¼Œå…¶ä¸­`CUDA_VISIBLE_DEVICES=0`æŒ‡å®šäº†ç¼–å·ä¸º0çš„GPUç”¨äºæ­¤æ¬¡è®­ç»ƒã€‚
* `model_name`: æŒ‡å®šæ‰€éœ€çš„**æ¨¡å‹æ¶æ„åç§°**(7Bã€13Bã€Baseã€Chatå±äºåŒä¸€æ¨¡å‹æ¶æ„)ã€‚å½“å‰æ”¯æŒçš„æ¨¡å‹åŒ…æ‹¬ï¼š["`llama`", "`alpaca`", "`vicuna`", "`zhixi`", "`falcon`", "`baichuan`", "`chatglm`", "`qwen`", "`moss`", "`openba`"]ã€‚**è¯·æ³¨æ„**ï¼Œæ­¤å‚æ•°åº”ä¸ `--model_name_or_path` åŒºåˆ†ã€‚
* `model_name_or_path`: æ¨¡å‹è·¯å¾„, è¯·åˆ° [HuggingFace](https://huggingface.co/models) ä¸‹è½½ç›¸åº”æ¨¡å‹ã€‚
* `template`: ä½¿ç”¨çš„**æ¨¡æ¿åç§°**ï¼ŒåŒ…æ‹¬ï¼š`alpaca`, `baichuan`, `baichuan2`, `chatglm3`ç­‰, è¯·å‚è€ƒ [src/datamodule/template.py](./src/datamodule/template.py) æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„æ¨¡ç‰ˆåç§°, é»˜è®¤ä½¿ç”¨çš„æ˜¯`alpaca`æ¨¡æ¿, **`Chat`ç‰ˆæœ¬çš„æ¨¡å‹å»ºè®®ä½¿ç”¨é…å¥—çš„æ¨¡ç‰ˆ, Baseç‰ˆæœ¬æ¨¡å‹å¯é»˜è®¤ä½¿ç”¨`alpaca`**ã€‚
* `train_file`, `valid_file(å¯é€‰)`: è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„**æ–‡ä»¶è·¯å¾„**, æ³¨æ„ï¼šç›®å‰ä»…æ”¯æŒ**jsonæ ¼å¼**çš„æ–‡ä»¶, âš ï¸è‹¥ä¸æŒ‡å®š`valid_file`, å°†è‡ªåŠ¨ä»`train_file`ä¸­åˆ’åˆ†`val_set_size`ä¸ªæ•°æ®ä½œä¸ºéªŒè¯é›†ã€‚
* `output_dir`: LoRAå¾®è°ƒåçš„**æƒé‡å‚æ•°ä¿å­˜è·¯å¾„**ã€‚
* `val_set_size`: **éªŒè¯é›†çš„æ ·æœ¬æ•°é‡**, é»˜è®¤ä¸º1000ã€‚
* `per_device_train_batch_size`, `per_device_eval_batch_size`: æ¯å°GPUè®¾å¤‡ä¸Šçš„`batch_size`, æ ¹æ®æ˜¾å­˜å¤§å°è°ƒæ•´, RTX3090å»ºè®®è®¾ç½®2~4ã€‚
* `max_source_length`, `max_target_length`, `cutoff_len`: æœ€å¤§è¾“å…¥ã€è¾“å‡ºé•¿åº¦ã€æˆªæ–­é•¿åº¦, æˆªæ–­é•¿åº¦å¯ä»¥ç®€å•åœ°è§†ä½œæœ€å¤§è¾“å…¥é•¿åº¦ + æœ€å¤§è¾“å‡ºé•¿åº¦, éœ€æ ¹æ®å…·ä½“éœ€æ±‚å’Œæ˜¾å­˜å¤§å°è®¾ç½®åˆé€‚å€¼ã€‚
* å¦‚æœå‡ºç°åœ¨evalé˜¶æ®µåä¿å­˜æ¨¡å‹æ—¶çˆ†æ˜¾å­˜çš„æƒ…å†µ, è¯·è®¾ç½® `evaluation_strategy no`

> å¯é€šè¿‡è®¾ç½® `bits` = 4 è¿›è¡Œé‡åŒ–, RTX3090å»ºè®®é‡åŒ–ã€‚

* è¦äº†è§£æ›´å¤šå…³äº**å‚æ•°é…ç½®**çš„ä¿¡æ¯ï¼Œè¯·å‚è€ƒ [src/utils/args](./src/args) ç›®å½•ã€‚


å¾®è°ƒ`LLaMA2-13B-Chat`æ¨¡å‹çš„å…·ä½“è„šæœ¬å¯ä»¥åœ¨ [ft_scripts/fine_llama.bash](./ft_scripts/fine_llama.bash) ä¸­æ‰¾åˆ°ã€‚

å¾®è°ƒ`Baichuan2-13B-Chat`æ¨¡å‹çš„å…·ä½“è„šæœ¬å¯ä»¥åœ¨ [ft_scripts/fine_baichuan.bash](./ft_scripts/fine_baichuan.bash) ä¸­æ‰¾åˆ°ã€‚



## 4.é¢†åŸŸå†…æ•°æ®ç»§ç»­è®­ç»ƒ

å°½ç®¡ `Baichuan2-IEPile` å’Œ `LLaMA2-IEPile` æ¨¡å‹å·²åœ¨å¤šä¸ªé€šç”¨æ•°æ®é›†ä¸Šæ¥å—äº†å¹¿æ³›çš„æŒ‡ä»¤å¾®è°ƒï¼Œå¹¶å› æ­¤è·å¾—äº†ä¸€å®šçš„**é€šç”¨ä¿¡æ¯æŠ½å–èƒ½åŠ›**ï¼Œä½†å®ƒä»¬åœ¨**ç‰¹å®šé¢†åŸŸ**(å¦‚`æ³•å¾‹`ã€`æ•™è‚²`ã€`ç§‘å­¦`ã€`ç”µä¿¡`)çš„æ•°æ®å¤„ç†ä¸Šå¯èƒ½ä»æ˜¾ç¤ºå‡ºä¸€å®šçš„å±€é™æ€§ã€‚é’ˆå¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œå»ºè®®å¯¹è¿™äº›æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸçš„æ•°æ®é›†ä¸Šè¿›è¡Œ**äºŒæ¬¡è®­ç»ƒ**ã€‚è¿™å°†æœ‰åŠ©äºæ¨¡å‹æ›´å¥½åœ°é€‚åº”ç‰¹å®šé¢†åŸŸçš„è¯­ä¹‰å’Œç»“æ„ç‰¹å¾ï¼Œä»è€Œå¢å¼ºå…¶åœ¨**è¯¥é¢†åŸŸå†…çš„ä¿¡æ¯æŠ½å–èƒ½åŠ›**ã€‚


### 4.1è®­ç»ƒæ•°æ®è½¬æ¢

é¦–å…ˆ, éœ€è¦å°†**æ•°æ®æ ¼å¼åŒ–**ä»¥åŒ…å«`instruction`ã€`output`å­—æ®µã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªè„šæœ¬ [convert_func.py](./ie2instruction/convert_func.py)ï¼Œå®ƒå¯ä»¥å°†æ•°æ®æ‰¹é‡è½¬æ¢æˆæ¨¡å‹å¯ä»¥ç›´æ¥ä½¿ç”¨çš„æ ¼å¼ã€‚

> åœ¨ä½¿ç”¨ [convert_func.py](./ie2instruction/convert_func.py) è„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿å‚è€ƒäº† [data](./data) ç›®å½•ã€‚è¯¥ç›®å½•è¯¦ç»†è¯´æ˜äº†æ¯ç§ä»»åŠ¡æ‰€éœ€çš„æ•°æ®æ ¼å¼è¦æ±‚ã€‚ `sample.json` æè¿°äº†è½¬æ¢å‰æ•°æ®çš„æ ¼å¼ï¼Œ`schema.json` å±•ç¤ºäº† schema çš„ç»„ç»‡ç»“æ„ï¼Œ `train.json` æè¿°äº†è½¬æ¢åçš„æ•°æ®æ ¼å¼ã€‚

> æ­¤å¤–ï¼Œå¯ç›´æ¥ä½¿ç”¨åŒ…å«12ä¸ªä¸»é¢˜ï¼ˆå¦‚äººç‰©ã€äº¤é€šå·¥å…·ã€è‰ºæœ¯ä½œå“ã€è‡ªç„¶ç§‘å­¦ã€äººé€ ç‰©å“ã€å¤©æ–‡å¯¹è±¡ç­‰ï¼‰çš„ä¸­è‹±åŒè¯­ä¿¡æ¯æŠ½å–æ•°æ®é›† [zjunlp/InstructIE](https://huggingface.co/datasets/zjunlp/InstructIE)ã€‚


```bash
python ie2instruction/convert_func.py \
    --src_path data/NER/sample.json \
    --tgt_path data/NER/train.json \
    --schema_path data/NER/schema.json \
    --language zh \
    --task NER \
    --split_num 6 \
    --random_sort \
    --split train
```

* `language`: æ”¯æŒ`zh`, `en`ä¸¤ç§è¯­è¨€, ä¸åŒè¯­è¨€ä½¿ç”¨çš„æŒ‡ä»¤æ¨¡ç‰ˆä¸åŒã€‚
* `task`: ç›®å‰æ”¯æŒ['`RE`', '`NER`', '`EE`', '`EET`', '`EEA`']äº”ç±»ä»»åŠ¡ã€‚
* `split_num`: å®šä¹‰å•ä¸ªæŒ‡ä»¤ä¸­å¯åŒ…å«çš„æœ€å¤§schemaæ•°ç›®ã€‚é»˜è®¤å€¼ä¸º4ï¼Œè®¾ç½®ä¸º-1åˆ™ä¸è¿›è¡Œåˆ‡åˆ†ã€‚æ¨èçš„ä»»åŠ¡åˆ‡åˆ†æ•°é‡ä¾ä»»åŠ¡è€Œå¼‚ï¼š**NERå»ºè®®ä¸º6ï¼ŒREã€EEã€EETã€EEAå‡æ¨èä¸º4**ã€‚
* `random_sort`: æ˜¯å¦å¯¹æŒ‡ä»¤ä¸­çš„schemaéšæœºæ’åº, é»˜è®¤ä¸ºFalse, å³æŒ‰å­—æ¯é¡ºåºæ’åºã€‚
* `split`: æŒ‡å®šæ•°æ®é›†ç±»å‹ï¼Œå¯é€‰`train`æˆ–`test`ã€‚

è½¬æ¢åçš„è®­ç»ƒæ•°æ®å°†åŒ…å« `task`, `source`, `instruction`, `output` å››ä¸ªå­—æ®µã€‚


**`éš¾è´Ÿæ ·æœ¬ç”Ÿæˆ`**: ä¿ƒè¿›è¯­ä¹‰ç›¸è¿‘å®¹æ˜“æ··æ·†schemaå…±ç°, å‡å°‘è®­ç»ƒæ ·æœ¬é‡
```bash
python ie2instruction/convert_func.py \
    --src_path data/SPO/sample.json \
    --tgt_path data/SPO/train.json \
    --schema_path data/SPO/schema.json \
    --cluster_mode \
    --hard_negative_path data/hard_negative/SPO_DuIE2.0.json \
    --language zh \
    --task SPO \
    --split_num 4 \
    --random_sort \
    --split train
```

å¢åŠ `--cluster_mode`, `--hard_negative_path data/hard_negative/SPO_DuIE2.0.json` å‚æ•°, `--hard_negative_path`å¯¹åº”éš¾è´Ÿæ ·æœ¬å­—å…¸, [hard_dict.json](./data/hard_negative/hard_dict.json) ä¸­æœ‰IEPILEä¸­æ¶‰åŠçš„æ‰€æœ‰æ•°æ®é›†çš„éš¾è´Ÿæ ·æœ¬å­—å…¸ã€‚



### 4.2ç»§ç»­è®­ç»ƒ

**`LLaMA2-IEPile`** | **`Baichuan2-IEPile`** | **`LLaMA3-IEPile`** | **`Qwen1.5-IEPile`** | **`OneKE`** æ¨¡å‹ä¸‹è½½é“¾æ¥ï¼š[zjunlp/llama2-13b-iepile-lora](https://huggingface.co/zjunlp/llama2-13b-iepile-lora/tree/main) | [zjunlp/baichuan2-13b-iepile-lora](https://huggingface.co/zjunlp/baichuan2-13b-iepile-lora) | [zjunlp/llama3-8b-iepile-lora](https://huggingface.co/zjunlp/llama3-8b-iepile-lora) | [zjunlp/qwen1.5-14b-iepile-lora](https://huggingface.co/zjunlp/qwen1.5-14b-iepile-lora) | [zjunlp/OneKE](https://huggingface.co/zjunlp/OneKE)

| checkpoint_dir | model_name_or_path | moadel_name | fp16/bf16 | template | 
| --- | --- | --- | --- | --- |
| llama2-13b-iepile-lora | LLaMA2-13B-Chat | llama | bf16 | llama2 |
| baichuan2-13b-iepile-lora | BaiChuan2-13B-Chat | baichuan | bf16 | baichuan2 |
| llama3-8b-iepile-lora | LLaMA3-8B-Instruct | llama | bf16 | alpaca |
| qwen1.5-14b-iepile-lora | Qwen1.5-14B-Chat | qwen2 | bf16 | qwen |
| OneKE | OneKE | llama | bf16 | llama2_zh |


```bash
output_dir='lora/llama2-13b-chat-v1-continue'
mkdir -p ${output_dir}
CUDA_VISIBLE_DEVICES="0,1,2,3" torchrun --nproc_per_node=4 --master_port=1287 src/finetune.py \
    --do_train --do_eval \
    --overwrite_output_dir \
    --model_name_or_path 'models/llama2-13B-Chat' \
    --checkpoint_dir 'lora/llama2-13b-iepile-lora' \
    --stage 'sft' \
    --model_name 'llama' \
    --template 'llama2' \
    --train_file 'data/train.json' \
    --valid_file 'data/dev.json' \
    --output_dir=${output_dir} \
    --per_device_train_batch_size 2 \
    --per_device_eval_batch_size 2 \
    --gradient_accumulation_steps 4 \
    --preprocessing_num_workers 16 \
    --num_train_epochs 10 \
    --learning_rate 5e-5 \
    --max_grad_norm 0.5 \
    --optim "adamw_torch" \
    --max_source_length 400 \
    --cutoff_len 700 \
    --max_target_length 300 \
    --evaluation_strategy "epoch" \
    --save_strategy "epoch" \
    --save_total_limit 10 \
    --lora_r 64 \
    --lora_alpha 64 \
    --lora_dropout 0.05 \
    --bf16 
```


* å‚æ•°è¯´æ˜è¯·å‚è€ƒ[3.3LoRAå¾®è°ƒ](./README_CN.md#33loraå¾®è°ƒ)
* è‹¥è¦åŸºäºå¾®è°ƒåçš„LoRAæƒé‡ç»§ç»­è®­ç»ƒï¼Œä»…éœ€å°† `checkpoint_dir` å‚æ•°æŒ‡å‘LoRAæƒé‡è·¯å¾„ï¼Œä¾‹å¦‚è®¾ç½®ä¸º`'zjunlp/llama2-13b-iepile-lora'`ã€‚

> å¯é€šè¿‡è®¾ç½® `bits` = 4 è¿›è¡Œé‡åŒ–, RTX3090å»ºè®®é‡åŒ–ã€‚

> è¯·æ³¨æ„ï¼Œåœ¨ä½¿ç”¨ **`LLaMA2-IEPile`** æˆ– **`Baichuan2-IEPile`** æ—¶ï¼Œä¿æŒlora_rå’Œlora_alphaå‡ä¸º64ï¼Œå¯¹äºè¿™äº›å‚æ•°ï¼Œæˆ‘ä»¬ä¸æä¾›æ¨èè®¾ç½®ã€‚

* è‹¥è¦åŸºäºå¾®è°ƒåçš„æ¨¡å‹æƒé‡ç»§ç»­è®­ç»ƒï¼Œåªéœ€è®¾å®š `model_name_or_path` å‚æ•°ä¸ºæƒé‡è·¯å¾„ï¼Œå¦‚`'zjunlp/KnowLM-IE-v2'`ï¼Œæ— éœ€è®¾ç½®`checkpoint_dir`ã€‚


è„šæœ¬å¯ä»¥åœ¨ [ft_scripts/fine_continue.bash](./ft_scripts/fine_continue.bash) ä¸­æ‰¾åˆ°ã€‚


### 4.3OneKEç»§ç»­è®­ç»ƒ

#### 4.3.1å…¨ç›‘ç£è®­ç»ƒ

```bash
output_dir='lora/OneKE-continue'
mkdir -p ${output_dir}
CUDA_VISIBLE_DEVICES="0,1,2,3" torchrun --nproc_per_node=4 --master_port=1287 src/test_finetune.py \
    --do_train --do_eval \
    --overwrite_output_dir \
    --model_name_or_path 'models/OneKE' \
    --stage 'sft' \
    --model_name 'llama' \
    --template 'llama2_zh' \
    --train_file 'data/train.json' \
    --valid_file 'data/dev.json' \
    --output_dir=${output_dir} \
    --per_device_train_batch_size 2 \
    --per_device_eval_batch_size 2 \
    --gradient_accumulation_steps 4 \
    --preprocessing_num_workers 16 \
    --num_train_epochs 10 \
    --learning_rate 5e-5 \
    --max_grad_norm 0.5 \
    --optim "adamw_torch" \
    --max_source_length 400 \
    --cutoff_len 700 \
    --max_target_length 300 \
    --evaluation_strategy "epoch" \
    --save_strategy "epoch" \
    --save_total_limit 10 \
    --bf16 
```

#### 4.3.2Loraè®­ç»ƒ

```bash
output_dir='lora/OneKE-continue-lora'
mkdir -p ${output_dir}
CUDA_VISIBLE_DEVICES="0,1,2,3" torchrun --nproc_per_node=4 --master_port=1287 src/test_finetune.py \
    --do_train --do_eval \
    --overwrite_output_dir \
    --model_name_or_path 'models/OneKE' \
    --stage 'sft' \
    --model_name 'llama' \
    --template 'llama2_zh' \
    --train_file 'data/train.json' \
    --valid_file 'data/dev.json' \
    --output_dir=${output_dir} \
    --per_device_train_batch_size 2 \
    --per_device_eval_batch_size 2 \
    --gradient_accumulation_steps 4 \
    --preprocessing_num_workers 16 \
    --num_train_epochs 10 \
    --learning_rate 5e-5 \
    --max_grad_norm 0.5 \
    --optim "adamw_torch" \
    --max_source_length 400 \
    --cutoff_len 700 \
    --max_target_length 300 \
    --evaluation_strategy "epoch" \
    --save_strategy "epoch" \
    --save_total_limit 10 \
    --lora_r 64 \
    --lora_alpha 64 \
    --lora_dropout 0.05 \
    --bf16 
```


## 5.é¢„æµ‹



### 5.1æµ‹è¯•æ•°æ®è½¬æ¢

åœ¨å‡†å¤‡æµ‹è¯•æ•°æ®è½¬æ¢ä¹‹å‰ï¼Œè¯·è®¿é—® [data](./data) ç›®å½•ä»¥äº†è§£å„ä»»åŠ¡æ‰€éœ€çš„æ•°æ®ç»“æ„ï¼š1ï¼‰è¾“å…¥æ•°æ®æ ¼å¼å‚è§ `sample.json`ï¼›2ï¼‰schemaæ ¼å¼è¯·æŸ¥çœ‹ `schema.json`ï¼›3ï¼‰è½¬æ¢åæ•°æ®æ ¼å¼å¯å‚ç…§ `train.json`ã€‚**ä¸è®­ç»ƒæ•°æ®ä¸åŒ, æµ‹è¯•æ•°æ®çš„è¾“å…¥æ— éœ€åŒ…å«æ ‡æ³¨å­—æ®µï¼ˆ`entity`, `relation`, `event`ï¼‰**ã€‚


```bash
python ie2instruction/convert_func.py \
    --src_path data/NER/sample.json \
    --tgt_path data/NER/test.json \
    --schema_path data/NER/schema.json \
    --language zh \
    --task NER \
    --split_num 6 \
    --split test
```

è®¾ç½® `split` ä¸º **test** æ—¶ï¼Œè¯·æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©é€‚å½“çš„schemaæ•°é‡ï¼š**NERæ¨èä¸º6ï¼Œè€ŒREã€EEã€EETã€EEAæ¨èä¸º4**ã€‚è½¬æ¢åçš„æµ‹è¯•æ•°æ®å°†å«æœ‰`id`, `task`, `source`, `instruction`, `label`äº”ä¸ªå­—æ®µã€‚

`label` å­—æ®µå°†ç”¨äºåç»­è¯„ä¼°ã€‚è‹¥è¾“å…¥æ•°æ®ä¸­ç¼ºå°‘æ ‡æ³¨å­—æ®µï¼ˆ`entity`, `relation`, `event`ï¼‰ï¼Œåˆ™è½¬æ¢åçš„æµ‹è¯•æ•°æ®å°†ä¸åŒ…å«`label`å­—æ®µï¼Œé€‚ç”¨äºé‚£äº›æ— åŸå§‹æ ‡æ³¨æ•°æ®çš„åœºæ™¯ã€‚


### 5.2IEPileæµ‹è¯•æ•°æ®

ä¸‹è½½ **`IEPile`** æ•°æ®é›† [Google Drive](https://drive.google.com/file/d/1jPdvXOTTxlAmHkn5XkeaaCFXQkYJk5Ng/view?usp=sharing) | [Hugging Face](https://huggingface.co/datasets/zjunlp/iepile) | [WiseModel](https://wisemodel.cn/datasets/zjunlp/IEPile) | [ModelScpoe](https://modelscope.cn/datasets/ZJUNLP/IEPile)

æ–‡ä»¶æ ‘å¦‚ä¸‹æ‰€ç¤º

```bash
IEPile
â”œâ”€â”€ train.json      # Training Set
â”œâ”€â”€ dev.json        # Validation Set
â”œâ”€â”€ IE-en           # English Unified Format Data
â”‚   â”œâ”€â”€ NER
â”‚   â”‚   â”œâ”€â”€ CoNLL2003
â”‚   â”‚   â”‚   â”œâ”€â”€ train.json
â”‚   â”‚   â”‚   â”œâ”€â”€ dev.json
â”‚   â”‚   â”‚   â”œâ”€â”€ schema.json   # schema information file
â”‚   â”‚   â”‚   â””â”€â”€ test.json
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ RE
â”‚   â”œâ”€â”€ EE
â”‚   â”œâ”€â”€ EET
â”‚   â”œâ”€â”€ EEA
â”œâ”€â”€ IE-zh           # Chinese Unified Format Data
â”‚   â”œâ”€â”€ NER
â”‚   â”œâ”€â”€ RE
â”‚   â”œâ”€â”€ EE
â”‚   â”œâ”€â”€ EET
â”‚   â”œâ”€â”€ EEA
```

é€šè¿‡ä¸‹é¢è„šæœ¬å¯æ‰¹é‡è·å¾—æµ‹è¯•æŒ‡ä»¤æ•°æ®ï¼š

```bash
bash ie2instruction/eval_data_convert.bash
```

> éœ€è¦è®¾ç½®è„šæœ¬ä¸­ç¬¬ä¸€è¡Œ `dir_path` ä¸º IEPile æ•°æ®é›†å®é™…ç»å¯¹è·¯å¾„
> æ³¨æ„ï¼šç”±äºè½¬æ¢åschemaåºåˆ—ä¸­labelé¡ºåºå¯èƒ½ä¸ä¸€è‡´ï¼Œæ‰€ä»¥è¯„ä¼°ç»“æœå¯èƒ½ç•¥æœ‰åå·®


### 5.3åŸºç¡€æ¨¡å‹+Loraé¢„æµ‹

**`LLaMA2-IEPile`** | **`Baichuan2-IEPile`** æ¨¡å‹ä¸‹è½½é“¾æ¥ï¼š[zjunlp/llama2-13b-iepile-lora](https://huggingface.co/zjunlp/llama2-13b-iepile-lora/tree/main) | [zjunlp/baichuan2-13b-iepile-lora](https://huggingface.co/zjunlp/baichuan2-13b-iepile-lora)


| checkpoint_dir | model_name_or_path | moadel_name | fp16/bf16 | template | 
| --- | --- | --- | --- | --- |
| llama2-13b-iepile-lora | LLaMA2-13B-Chat | llama | bf16 | llama2 |
| baichuan2-13b-iepile-lora | BaiChuan2-13B-Chat | baichuan | bf16 | baichuan2 |
| llama3-8b-iepile-lora | LLaMA3-8B-Instruct | llama | bf16 | alpaca |
| qwen1.5-14b-iepile-lora | Qwen1.5-14B-Chat | qwen2 | bf16 | qwen |


âš ï¸ æ³¨æ„ä½¿ç”¨**åŸºç¡€æ¨¡å‹+Loraé¢„æµ‹**æ—¶ä¸ä»…éœ€è¦ä¸‹è½½Loraæƒé‡å‚æ•°, è¿˜è¦ä¸‹è½½åŸºç¡€æ¨¡å‹å‚æ•°ã€‚ä¾‹å¦‚: ä½¿ç”¨`baichuan2-13b-iepile-lora`(--checkpoint_dir), è¿˜éœ€è¦ä¸‹è½½`BaiChuan2-13B-Chat`(--model_name_or_path), ğŸš«**ä¸èƒ½**åªè®¾ç½® `--model_name_or_path lora/baichuan2-13b-iepile-lora`ã€‚


```bash
CUDA_VISIBLE_DEVICES=0 python src/inference.py \
    --stage sft \
    --model_name_or_path 'models/llama2-13B-Chat' \
    --checkpoint_dir 'lora/llama2-13b-IEPile-lora' \
    --model_name 'llama' \
    --template 'llama2' \
    --do_predict \
    --input_file 'data/input.json' \
    --output_file 'results/llama2-13b-IEPile-lora_output.json' \
    --finetuning_type lora \
    --output_dir 'lora/test' \
    --predict_with_generate \
    --cutoff_len 512 \
    --bf16 \
    --max_new_tokens 300
```

* åœ¨è¿›è¡Œæ¨ç†æ—¶ï¼Œ`model_name`, `template`, å’Œ `bf16` å¿…é¡»ä¸è®­ç»ƒæ—¶çš„è®¾ç½®ç›¸åŒã€‚
* `model_name_or_path`: æŒ‡å®šæ‰€ä½¿ç”¨çš„åŸºç¡€æ¨¡å‹è·¯å¾„ï¼Œå¿…é¡»ä¸ç›¸åº”çš„LoRAæ¨¡å‹åŒ¹é…ã€‚
* `checkpoint_dir`: LoRAçš„æƒé‡æ–‡ä»¶è·¯å¾„ã€‚
* `output_dir`: æ­¤å‚æ•°åœ¨æ¨ç†æ—¶ä¸èµ·ä½œç”¨ï¼Œå¯ä»¥éšæ„æŒ‡å®šä¸€ä¸ªè·¯å¾„ã€‚
* `input_file`, `output_file`: åˆ†åˆ«æŒ‡å®šè¾“å…¥çš„æµ‹è¯•æ–‡ä»¶è·¯å¾„å’Œé¢„æµ‹ç»“æœçš„è¾“å‡ºæ–‡ä»¶è·¯å¾„ã€‚
* `cutoff_len`, `max_new_tokens`: è®¾ç½®æœ€å¤§çš„è¾“å…¥é•¿åº¦å’Œç”Ÿæˆçš„æ–°tokenæ•°é‡ï¼Œæ ¹æ®æ˜¾å­˜å¤§å°è¿›è¡Œè°ƒæ•´ã€‚


> å¯é€šè¿‡è®¾ç½® `bits` = 4 è¿›è¡Œé‡åŒ–, RTX3090å»ºè®®é‡åŒ–ã€‚

### 5.4IEä¸“ç”¨æ¨¡å‹é¢„æµ‹


| checkpoint_dir | model_name_or_path | moadel_name | fp16/bf16 | template | 
| --- | --- | --- | --- | --- |
| OneKE | OneKE | llama | bf16 | llama2_zh |


**`OneKE(based on chinese-alpaca2)`** æ¨¡å‹ä¸‹è½½é“¾æ¥ï¼š[zjunlp/OneKE](https://huggingface.co/zjunlp/OneKE)

```bash
CUDA_VISIBLE_DEVICES=0 python src/inference.py \
    --stage sft \
    --model_name_or_path 'models/OneKE' \
    --model_name 'llama' \
    --template 'llama2_zh' \
    --do_predict \
    --input_file 'data/NER/test.json' \
    --output_file 'results/OneKE_output.json' \
    --output_dir 'lora/test' \
    --predict_with_generate \
    --cutoff_len 512 \
    --bf16 \
    --max_new_tokens 300 \
    --bits 4
```

`model_name_or_path`: IEä¸“ç”¨æ¨¡å‹æƒé‡è·¯å¾„


## æ¨¡å‹ä½¿ç”¨

### æ¨¡å‹ä¸‹è½½

[HuggingFace](https://huggingface.co/zjunlp/OneKE), [ModelScope](https://modelscope.cn/models/ZJUNLP/OneKE), [WiseModel](https://wisemodel.cn/models/zjunlp/OneKE)

### ç¯å¢ƒå®‰è£…

```bash
conda create -n OneKE python=3.9
conda activate OneKE
pip install -r requirements.txt
```

### å¿«é€Ÿè¿è¡Œ

è®­ç»ƒå’Œæ¨ç†å»ºè®®è‡³å°‘å…·å¤‡**20GBçš„æ˜¾å­˜**

```python
import torch
from transformers import (
    AutoConfig,
    AutoTokenizer,
    AutoModelForCausalLM,
    GenerationConfig,
    BitsAndBytesConfig
)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_path = 'zjunlp/OneKE' #é€‰æ‹©ä½ ä¸‹è½½çš„æ¨¡å‹å­˜å‚¨åœ¨æœ¬åœ°çš„ä½ç½®
config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)


# 4bité‡åŒ–OneKE
quantization_config=BitsAndBytesConfig(     
    load_in_4bit=True,
    llm_int8_threshold=6.0,
    llm_int8_has_fp16_weight=False,
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
)

model = AutoModelForCausalLM.from_pretrained(
    model_path,
    config=config,
    device_map="auto",  
    quantization_config=quantization_config,
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
)
model.eval()


system_prompt = '<<SYS>>\nYou are a helpful assistant. ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚\n<</SYS>>\n\n'
sintruct = "{\"instruction\": \"You are an expert in named entity recognition. Please extract entities that match the schema definition from the input. Return an empty list if the entity type does not exist. Please respond in the format of a JSON string.\", \"schema\": [\"person\", \"organization\", \"else\", \"location\"], \"input\": \"284 Robert Allenby ( Australia ) 69 71 71 73 , Miguel Angel Martin ( Spain ) 75 70 71 68 ( Allenby won at first play-off hole )\"}"
sintruct = '[INST] ' + system_prompt + sintruct + '[/INST]'

input_ids = tokenizer.encode(sintruct, return_tensors="pt").to(device)
input_length = input_ids.size(1)
generation_output = model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_length=1024, max_new_tokens=512, return_dict_in_generate=True), pad_token_id=tokenizer.eos_token_id)
generation_output = generation_output.sequences[0]
generation_output = generation_output[input_length:]
output = tokenizer.decode(generation_output, skip_special_tokens=True)

print(output)
```

### vLLM æ¨ç†

vLLMçš„ç¯å¢ƒé…ç½®å¯è§å…¶å®˜æ–¹å®‰è£…é…ç½®æ–‡æ¡£ ([Installation](https://vllm.readthedocs.io/en/latest/getting_started/installation.html))

éƒ¨ç½²æœåŠ¡

```bash
python -m vllm.entrypoints.openai.api_server --model zjunlp/OneKE
```

ç»ˆç«¯ä½¿ç”¨Apiæ¨ç†

```bash
curl http://localhost:8000/v1/completions -H "Content-Type: application/json" -d '{"model": "/data2/lkw/OneKE", "prompt": "[INST] <<SYS>>You are a helpful assistant. ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚<</SYS>>{\"instruction\": \"You are an expert in named entity recognition. Please extract entities that match the schema definition from the input. Return an empty list if the entity type does not exist. Please respond in the format of a JSON string.\", \"schema\": [\"person\", \"organization\", \"else\", \"location\"], \"input\": \"284 Robert Allenby ( Australia ) 69 71 71 73 , Miguel Angel Martin ( Spain ) 75 70 71 68 ( Allenby won at first play-off hole )\"}[/INST]", "max_tokens": 1024, "temperature": 0}'
```


### ollama æ¨ç†

ollama çš„ç¯å¢ƒé…ç½®å¯è§å…¶å®˜æ–¹æ–‡æ¡£ https://github.com/ollama/ollama/tree/main

```bash
curl -fsSL https://ollama.com/install.sh | sh
```


åˆ›å»º Modelfile æ–‡ä»¶

```bash
FROM /disk/disk_20T/ghh/OneKE-13B-BF16.gguf
PARAMETER temperature 0
PARAMETER num_ctx 4096
TEMPLATE """[INST] <<SYS>>You are a helpful assistant. ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚<</SYS>>{{ .Prompt }}[/INST]"""
```

å¯åŠ¨ ollama

```bash
ollama serve
```

åœ¨å¦ä¸€ä¸ªç»ˆç«¯çª—å£è¾“å…¥å‘½ä»¤

```bash
ollama create oneke -f Modelfile

ollama run oneke
```

è¾“å…¥å’Œè¾“å‡º

```
>>> {\"instruction\": \"ä½ æ˜¯ä¸“é—¨è¿›è¡Œå®ä½“æŠ½å–çš„ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„å®ä½“ï¼Œä¸å­˜åœ¨çš„å®ä½“ç±»å‹
... è¿”å›ç©ºåˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚\", \"schema\": [\"äººç‰©\", \"åœ°ç†ä½ç½®\", \"ç»„ç»‡æœºæ„\"], \"input
... \": \"åœ¨è¿™é‡Œæ•å¼Ÿä¸æ­ä¹‹ç½ªï¼Œæ•¢åœ¨å°Šå‰ä¸€è¯¤ï¼šå‰äººè®ºä¹¦ï¼Œæ¯æ›°â€œå­—å­—æœ‰æ¥å†ï¼Œç¬”ç¬”æœ‰å‡ºå¤„â€ï¼Œç»†è¯»å…¬å­—ï¼Œä½•å°è·³å‡ºå‰äºº
... è—©ç¯±ï¼Œè‡ªéš¶å˜è€Œåï¼Œç›´è‡³æ˜å­£ï¼Œå…„æœ‰ä½•æ–°å‡ºï¼Ÿ\"}
 {"äººç‰©": [], "åœ°ç†ä½ç½®": [], "ç»„ç»‡æœºæ„": []}

>>> {\"instruction\": \"ä½ æ˜¯ä¸“é—¨è¿›è¡Œå®ä½“æŠ½å–çš„ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„å®ä½“ï¼Œä¸å­˜åœ¨çš„å®ä½“ç±»å‹
... è¿”å›ç©ºåˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚\", \"schema\": [\"ç»„ç»‡æœºæ„\", \"åœ°ç†ä½ç½®\", \"äººç‰©\"], \"input
... \": \"èƒ¡è€è¯´ï¼Œå½“ç”»ç”»ç–²å€¦æ—¶å°±åˆ°é™¢é‡Œå»çœ‹çœ‹ï¼Œç»™è¿™ç›†èŠ±æµ‡ç‚¹æ°´ï¼Œç»™é‚£æ£µèŠ±å‰ªå‰ªæï¼Œå›æ¥å†æ¥ç€ç”»ï¼Œç”»ç´¯äº†å†å‡ºå»ï¼Œ
... å¦‚æ­¤å¾ªç¯å¾€å¤ï¼Œè„‘ä½“ç»“åˆï¼Œæœ‰ç›Šå¥åº·ï¼Œèƒœè¿‡åƒè¯ã€‚\"}
 {"ç»„ç»‡æœºæ„": [], "åœ°ç†ä½ç½®": [], "äººç‰©": ["èƒ¡"]}

>>> {\"instruction\": \"ä½ æ˜¯ä¸“é—¨è¿›è¡Œäº‹ä»¶æå–çš„ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„äº‹ä»¶ï¼Œä¸å­˜åœ¨çš„äº‹ä»¶è¿”å›
... ç©ºåˆ—è¡¨ï¼Œä¸å­˜åœ¨çš„è®ºå…ƒè¿”å›NANï¼Œå¦‚æœè®ºå…ƒå­˜åœ¨å¤šå€¼è¯·è¿”å›åˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚\", \"schema\": [{
... \"event_type\": \"äº§å“è¡Œä¸º-è·å¥–\", \"trigger\": true, \"arguments\": [\"è·å¥–äºº\", \"é¢å¥–æœºæ„\", \"å¥–é¡¹\
... ", \"æ—¶é—´\"]}, {\"event_type\": \"ç»„ç»‡è¡Œä¸º-ç½¢å·¥\", \"trigger\": true, \"arguments\": [\"ç½¢å·¥äººæ•°\", \"
... ç½¢å·¥äººå‘˜\", \"æ‰€å±ç»„ç»‡\", \"æ—¶é—´\"]}, {\"event_type\": \"ç»„ç»‡å…³ç³»-è£å‘˜\", \"trigger\": true, \"argument
... s\": [\"è£å‘˜æ–¹\", \"æ—¶é—´\", \"è£å‘˜äººæ•°\"]}, {\"event_type\": \"ç»„ç»‡å…³ç³»-è§£æ•£\", \"trigger\": true, \"ar
... guments\": [\"è§£æ•£æ–¹\", \"æ—¶é—´\"]}], \"input\": \"æ¶ˆå¤±çš„â€œå¤–ä¼å…‰ç¯â€ï¼Œ5æœˆä»½åœ¨åè£å‘˜900ä½™äººï¼Œé¦™é¥½é¥½å˜â€œè‡­â€
... äº†\"}
 {"äº§å“è¡Œä¸º-è·å¥–": [], "ç»„ç»‡è¡Œä¸º-ç½¢å·¥": [], "ç»„ç»‡å…³ç³»-è£å‘˜": [{"trigger": "è£å‘˜", "arguments": {"è£å‘˜æ–¹
": "NAN", "æ—¶é—´": "5æœˆä»½", "è£å‘˜äººæ•°": "900ä½™äºº"}}], "ç»„ç»‡å…³ç³»-è§£æ•£": []}
```


é€€å‡ºååˆ é™¤

```bash
ollama stop oneke

ollama rm oneke
```


### åœ¨ Mac ä¸Šæ¨ç†

```python
import torch
from transformers import (
    AutoConfig,
    AutoTokenizer,
    AutoModelForCausalLM,
    GenerationConfig,
    BitsAndBytesConfig
)

device = torch.device("mps")
model_path = 'zjunlp/OneKE' #é€‰æ‹©ä½ ä¸‹è½½çš„æ¨¡å‹å­˜å‚¨åœ¨æœ¬åœ°çš„ä½ç½®
config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)

model = AutoModelForCausalLM.from_pretrained(
    model_path,
    config=config,
    device_map="auto",  
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
)
model.eval()
model = model.to(device)
```

`PYTORCH_ENABLE_MPS_FALLBACK=1 python test.py` å‘½ä»¤è¡Œå¯åŠ¨ã€‚


### å¤šå¡æ¨ç†

```python
import torch
from transformers import AutoConfig, AutoModel, AutoTokenizer, GenerationConfig
from accelerate import init_empty_weights, infer_auto_device_map, load_checkpoint_in_model, dispatch_model

max_memory_each_gpu = '15GiB' 
gpu_device_ids = [0, 1] 
no_split_module_classes = ["LlamaDecoderLayer"]
model_path = '/disk/disk_20T/ghh/OneKE' #é€‰æ‹©ä½ ä¸‹è½½çš„æ¨¡å‹å­˜å‚¨åœ¨æœ¬åœ°çš„ä½ç½®

max_memory = {
    device_id: max_memory_each_gpu for device_id in gpu_device_ids
}

config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)

with init_empty_weights():
    model = AutoModel.from_config(config, torch_dtype=torch.float16, trust_remote_code=True)

device_map = infer_auto_device_map(model, max_memory=max_memory, no_split_module_classes=no_split_module_classes)

print("auto determined device_map", device_map)
device_map["llm.model.embed_tokens"] = 0
device_map["llm.model.layers.0"] = 0
device_map["llm.lm_head"] = 0
device_map["vpm"] = 0
device_map["resampler"] = 0
print("modified device_map", device_map)

load_checkpoint_in_model(model, model_path, device_map=device_map)

model = dispatch_model(model, device_map=device_map)
torch.set_grad_enabled(False)
model.eval()


system_prompt = '<<SYS>>\nYou are a helpful assistant. ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚\n<</SYS>>\n\n'
sintruct = "{\"instruction\": \"You are an expert in named entity recognition. Please extract entities that match the schema definition from the input. Return an empty list if the entity type does not exist. Please respond in the format of a JSON string.\", \"schema\": [\"person\", \"organization\", \"else\", \"location\"], \"input\": \"284 Robert Allenby ( Australia ) 69 71 71 73 , Miguel Angel Martin ( Spain ) 75 70 71 68 ( Allenby won at first play-off hole )\"}"
sintruct = '[INST] ' + system_prompt + sintruct + '[/INST]'

input_ids = tokenizer.encode(sintruct, return_tensors="pt")
input_length = input_ids.size(1)
generation_output = model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_length=1024, max_new_tokens=512, return_dict_in_generate=True), pad_token_id=tokenizer.eos_token_id)
generation_output = generation_output.sequences[0]
generation_output = generation_output[input_length:]
output = tokenizer.decode(generation_output, skip_special_tokens=True)

print(output)
```




## 6.è¯„ä¼°

æˆ‘ä»¬æä¾›äº†è¯„ä¼°å„ä¸ªä»»åŠ¡F1åˆ†æ•°çš„è„šæœ¬ã€‚

```bash
python ie2instruction/eval_func.py \
  --path1 data/NER/processed.json \
  --task NER 
```

* `task`: ç›®å‰æ”¯æŒ['RE', 'NER', 'EE', 'EET', 'EEA']äº”ç±»ä»»åŠ¡ã€‚
* å¯ä»¥è®¾ç½® `sort_by` ä¸º `source`, åˆ†åˆ«è®¡ç®—æ¯ä¸ªæ•°æ®é›†ä¸Šçš„F1åˆ†æ•°ã€‚



## 7.å£°æ˜å’Œè®¸å¯

æˆ‘ä»¬è®¤ä¸ºæ ‡æ³¨æ•°æ®è•´å«ç€äººç±»çš„æ™ºæ…§å®åº“ï¼Œå®ƒçš„å­˜åœ¨æ˜¯ä¸ºäº†ä¿ƒè¿›å…¨äººç±»çš„åˆ©ç›Šï¼Œå¹¶æœ‰åŠ©äºæå‡æˆ‘ä»¬çš„ç”Ÿæ´»è´¨é‡ã€‚æˆ‘ä»¬å¼ºçƒˆæ•¦ä¿ƒæ‰€æœ‰çš„ç”¨æˆ·ä¸è¦å°†æˆ‘ä»¬çš„è¯­æ–™åº“ç”¨äºä»»ä½•å¯èƒ½å¯¹å›½å®¶æˆ–å…¬å…±å®‰å…¨é€ æˆä¼¤å®³ã€è¿åæ³•å¾‹æ³•è§„çš„è¡Œä¸ºã€‚
æˆ‘ä»¬ç«­å°½æ‰€èƒ½åœ°ä¿è¯æ‰€æä¾›æ•°æ®çš„è´¨é‡ä¸å…¶åˆæ³•æ€§ã€‚ä½†æˆ‘ä»¬ä¹Ÿæ„è¯†åˆ°ï¼Œå°½ç®¡å¦‚æ­¤ï¼Œå¯èƒ½è¿˜æ˜¯å­˜åœ¨ä¸€äº›ä¸å¯é¢„è§çš„é—®é¢˜ï¼Œè¯¸å¦‚æ•°æ®ä¿æŠ¤çš„æ‹…å¿§ä»¥åŠæ•°æ®è¢«æ»¥ç”¨å¯èƒ½å¼•èµ·çš„é£é™©å’Œé—®é¢˜ã€‚å¯¹äºè¿™äº›æ½œåœ¨çš„é—®é¢˜ï¼Œæˆ‘ä»¬å°†ä¸æ‰¿æ‹…è´£ä»»ã€‚
å¯¹äºé‚£äº›å—é™äºæ¯”[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)åè®®æ›´ä¸ºä¸¥æ ¼çš„ä½¿ç”¨è®¸å¯çš„åŸå§‹æ•°æ®ï¼ŒIEPileå°†æªå®ˆé‚£äº›è¾ƒä¸ºä¸¥æ ¼çš„æ¡æ¬¾ã€‚åœ¨å…¶ä»–æ‰€æœ‰æƒ…å½¢ä¸‹ï¼Œæˆ‘ä»¬çš„æ“ä½œå°†åŸºäº[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)è®¸å¯åè®®ã€‚



## 8.å±€é™

ä»æ•°æ®è§’åº¦æ¥çœ‹ï¼Œæˆ‘ä»¬çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨åŸºäºschemaçš„ä¿¡æ¯æŠ½å–ï¼ˆIEï¼‰ä¸Šï¼Œè¿™é™åˆ¶äº†æˆ‘ä»¬å°†ç ”ç©¶æˆæœæ¨å¹¿è‡³ä¸éµå¾ªæˆ‘ä»¬ç‰¹å®šæ ¼å¼è¦æ±‚çš„äººç±»æŒ‡ä»¤çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ²¡æœ‰æ¢ç´¢å¼€æ”¾ä¿¡æ¯æŠ½å–ï¼ˆOpen IEï¼‰é¢†åŸŸï¼›ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬å»é™¤schemaçº¦æŸï¼Œæˆ‘ä»¬çš„æ•°æ®é›†å°†é€‚ç”¨äºå¼€æ”¾ä¿¡æ¯æŠ½å–åœºæ™¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ•°æ®é›†ç›®å‰ä»…åŒ…å«è‹±è¯­å’Œä¸­æ–‡æ•°æ®ï¼Œåœ¨æœªæ¥ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤ŸåŒ…å«æ›´å¤šè¯­è¨€çš„æ•°æ®ã€‚
ä»æ¨¡å‹çš„è§’åº¦æ¥çœ‹ï¼Œç”±äºè®¡ç®—èµ„æºçš„é™åˆ¶ï¼Œæˆ‘ä»¬çš„ç ”ç©¶ä»…è¯„ä¼°äº†ä¸¤ä¸ªæ¨¡å‹ï¼šBaichuanå’ŒLLaMAï¼Œä»¥åŠä¸€äº›åŸºçº¿æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ•°æ®é›†å¯ä»¥åº”ç”¨äºä»»ä½•å…¶ä»–çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œå¦‚Qwenã€ChatGLMã€‚


## 9.å¼•ç”¨
å¦‚æœæ‚¨ä½¿ç”¨IEPileæˆ–ä»£ç ï¼Œè¯·å¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š
```bibtex
@article{DBLP:journals/corr/abs-2402-14710,
  author       = {Honghao Gui and
                  Lin Yuan and
                  Hongbin Ye and
                  Ningyu Zhang and
                  Mengshu Sun and
                  Lei Liang and
                  Huajun Chen},
  title        = {IEPile: Unearthing Large-Scale Schema-Based Information Extraction
                  Corpus},
  journal      = {CoRR},
  volume       = {abs/2402.14710},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2402.14710},
  doi          = {10.48550/ARXIV.2402.14710},
  eprinttype    = {arXiv},
  eprint       = {2402.14710},
  timestamp    = {Tue, 09 Apr 2024 07:32:43 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2402-14710.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
```


## 10.è‡´è°¢
æˆ‘ä»¬éå¸¸æ„Ÿè°¢[MathPile](mathpile)å’Œ[KnowledgePile](https://huggingface.co/datasets/Query-of-CC/Knowledge_Pile)é¡¹ç›®æä¾›çš„å®è´µçµæ„Ÿã€‚æˆ‘ä»¬å¯¹ä»¥ä¸‹æ•°æ®é›†æ„å»ºè€…å’Œç»´æŠ¤è€…è¡¨ç¤ºç‰¹åˆ«çš„è°¢æ„ï¼š[AnatEM](https://doi.org/10.1093/BIOINFORMATICS/BTT580)ã€[BC2GM](https://link.springer.com/chapter/10.1007/978-3-030-68763-2_48)ã€[BC4CHEMD](https://link.springer.com/chapter/10.1007/978-3-030-68763-2_48)ã€[NCBI-Disease](https://linkinghub.elsevier.com/retrieve/pii/S1532046413001974)ã€[BC5CDR](https://openreview.net/pdf?id=9EAQVEINuum)ã€[HarveyNER](https://aclanthology.org/2022.naacl-main.243/)ã€[CoNLL2003](https://aclanthology.org/W03-0419/)ã€[GENIA](https://pubmed.ncbi.nlm.nih.gov/12855455/)ã€[ACE2005](https://catalog.ldc.upenn.edu/LDC2006T06)ã€[MIT Restaurant](https://ieeexplore.ieee.org/document/6639301)ã€[MIT Movie](https://ieeexplore.ieee.org/document/6639301)ã€[FabNER](https://link.springer.com/article/10.1007/s10845-021-01807-x)ã€[MultiNERD](https://aclanthology.org/2022.findings-naacl.60/)ã€[Ontonotes](https://aclanthology.org/N09-4006/)ã€[FindVehicle](https://arxiv.org/abs/2304.10893)ã€[CrossNER](https://ojs.aaai.org/index.php/AAAI/article/view/17587)ã€[MSRA NER](https://aclanthology.org/W06-0115/)ã€[Resume NER](https://aclanthology.org/P18-1144/)ã€[CLUE NER](https://arxiv.org/abs/2001.04351)ã€[Weibo NER](https://aclanthology.org/D15-1064/)ã€[Boson](https://github.com/InsaneLife/ChineseNLPCorpus/tree/master/NER/boson)ã€[ADE Corpus](https://jbiomedsem.biomedcentral.com/articles/10.1186/2041-1480-3-15)ã€[GIDS](https://arxiv.org/abs/1804.06987)ã€[CoNLL2004](https://aclanthology.org/W04-2412/)ã€[SciERC](https://aclanthology.org/D18-1360/)ã€[Semeval-RE](https://aclanthology.org/S10-1006/)ã€[NYT11-HRL](https://ojs.aaai.org/index.php/AAAI/article/view/4688)ã€[KBP37](https://arxiv.org/abs/1508.01006)ã€[NYT](https://link.springer.com/chapter/10.1007/978-3-642-15939-8_10)ã€[Wiki-ZSL](https://aclanthology.org/2021.naacl-main.272/)ã€[FewRel](https://aclanthology.org/D18-1514/)ã€[CMeIE](https://link.springer.com/chapter/10.1007/978-3-030-60450-9_22)ã€[DuIE](https://link.springer.com/chapter/10.1007/978-3-030-32236-6_72)ã€[COAE2016](https://github.com/Sewens/COAE2016)ã€[IPRE](https://arxiv.org/abs/1907.12801)ã€[SKE2020](https://aistudio.baidu.com/datasetdetail/177191)ã€[CASIE](https://ojs.aaai.org/index.php/AAAI/article/view/6401)ã€[PHEE](https://aclanthology.org/2022.emnlp-main.376/)ã€[CrudeOilNews](https://aclanthology.org/2022.lrec-1.49/)ã€[RAMS](https://aclanthology.org/2020.acl-main.718/)ã€[WikiEvents](https://aclanthology.org/2021.naacl-main.69/)ã€[DuEE](https://link.springer.com/chapter/10.1007/978-3-030-60457-8_44)ã€[DuEE-Fin](https://link.springer.com/chapter/10.1007/978-3-031-17120-8_14)ã€[FewFC](https://ojs.aaai.org/index.php/AAAI/article/view/17720)ã€[CCF law](https://aistudio.baidu.com/projectdetail/4201483)ç­‰ï¼Œè¿™äº›æ•°æ®é›†æå¤§åœ°ä¿ƒè¿›äº†æœ¬ç ”ç©¶çš„è¿›å±•ã€‚æˆ‘ä»¬ä¹Ÿè¦å¯¹[InstructUIE](http://arxiv.org/abs/2304.08085)ä¸[YAYI-UIE](http://arxiv.org/abs/2312.15548)ä¸ºæ•°æ®å’Œæ¨¡å‹åœ¨ä¿¡æ¯æŠ½å–é¢†åŸŸåšå‡ºçš„å®è´µè´¡çŒ®è¡¨ç¤ºæ„Ÿæ¿€ã€‚æˆ‘ä»¬çš„ç ”ç©¶æˆæœåŒæ ·å¾—ç›Šäºä»–ä»¬çš„åˆ›æ–°å’ŒåŠªåŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¦å¯¹[hiyouga/LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)è¡¨ç¤ºè¡·å¿ƒçš„æ„Ÿè°¢ï¼Œæˆ‘ä»¬çš„å¾®è°ƒä»£ç å®ç°åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå‚è€ƒäº†ä»–ä»¬çš„å·¥ä½œã€‚é€šè¿‡è¿™äº›å­¦æœ¯èµ„æºçš„è¾…åŠ©ï¼Œæˆ‘ä»¬å¾—ä»¥å®Œæˆæœ¬é¡¹ç ”ç©¶ï¼Œå¯¹æ­¤æˆ‘ä»¬æ·±è¡¨æ„Ÿæ¿€ã€‚
